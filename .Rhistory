samps<-read.csv("~/Downloads/hzar.input.csv")
# set Chain length
chainLength=100
#write function to run 3 different hzar models and store the output in a single list
run3hzarmodels<-function(input.trait=NULL, begin=NULL,end=NULL){
## create empty object to hold results
x <- list() #designate the firs trait 'Comp.1'
x$models <- list() #Space to hold the models to fit
x$fitRs <- list() #Space to hold the compiled fit requests
x$runs <- list() #Space to hold the output data chains
x$analysis <- list() #Space to hold the analysed data
#add input observed data to list
x$obs<-input.trait
#load the three different models we will test
#min and max values fixed to observed data, no exponential tails
x$models[["modelI"]]<-hzar.makeCline1DFreq(x$obs, "fixed", "none")
#min and max values estimated as free parameters, no exponential tails
x$models[["modelII"]]<-hzar.makeCline1DFreq(x$obs, "free", "none")
#min and max values estimated as free paramaters, tails estimated as independent paramaters
x$models[["modelIII"]]<-hzar.makeCline1DFreq(x$obs, "free", "both")
#modify all models to focus on observed region
x$models <- sapply(x$models, hzar.model.addBoxReq, begin, end, simplify=FALSE)
## Compile each of the models to prepare for fitting
#fit each of the 3 models we set up to the observed data
x$fitRs$init <- sapply(x$models, hzar.first.fitRequest.old.ML, obsData=x$obs, verbose=FALSE, simplify=FALSE)
#update settings for the fitter using chainLength created before
x$fitRs$init$modelI$mcmcParam$chainLength <- chainLength
x$fitRs$init$modelI$mcmcParam$burnin <- chainLength %/% 10
x$fitRs$init$modelII$mcmcParam$chainLength <- chainLength
x$fitRs$init$modelII$mcmcParam$burnin <- chainLength %/% 10
x$fitRs$init$modelIII$mcmcParam$chainLength <- chainLength
x$fitRs$init$modelIII$mcmcParam$burnin <- chainLength %/% 10
## Run just one of the models for an initial chain
x$runs$init$modelI <-hzar.doFit(x$fitRs$init$modelI)
## Run another model for an initial chain
x$runs$init$modelII <- hzar.doFit(x$fitRs$init$modelII)
## Run another model for an initial chain
x$runs$init$modelIII <- hzar.doFit(x$fitRs$init$modelIII)
## Compile a new set of fit requests using the initial chains
x$fitRs$chains <-lapply(x$runs$init,hzar.next.fitRequest)
## Replicate each fit request 3 times
x$fitRs$chains <-hzar.multiFitRequest(x$fitRs$chains,each=3)
##Run a chain of 3 runs for every fit request
x$runs$chains <-hzar.doChain.multi(x$fitRs$chains,doPar=TRUE,inOrder=FALSE,count=3)
return(x)
}
check.convergence<-function(input.hzar=NULL){
## Check for convergence
print("did chains from modelI converge?")
plot(hzar.mcmc.bindLL(input.hzar$runs$init$modelIII))  ## Plot the trace model I
print("did chains from modelII converge?")
plot(hzar.mcmc.bindLL(input.hzar$runs$init$modelIII))  ## Plot the trace model II
print("did chains from modelIII converge?")
plot(hzar.mcmc.bindLL(input.hzar$runs$init$modelIII))  ## Plot the trace model III
}
#write function to do the processing necessary before plotting
analyze.hzar.output<-function(input.hzar=NULL, input.var=NULL){
#add a null model where allele frequency is independent of sampling locality
input.hzar$analysis$initDGs <- list(nullModel =  hzar.dataGroup.null(input.hzar$obs))
#start aggregation of data for analysis
#create a model data group for each model from the initial runs
input.hzar$analysis$initDGs$modelI<- hzar.dataGroup.add(input.hzar$runs$init$modelI)
input.hzar$analysis$initDGs$modelII <-hzar.dataGroup.add(input.hzar$runs$init$modelII)
input.hzar$analysis$initDGs$modelIII<- hzar.dataGroup.add(input.hzar$runs$init$modelIII)
##create a hzar.obsDataGroup object from the four hzar.dataGroup just created, copying the naming scheme
input.hzar$analysis$oDG<-hzar.make.obsDataGroup(input.hzar$analysis$initDGs)
input.hzar$analysis$oDG <- hzar.copyModelLabels(input.hzar$analysis$initDGs,input.hzar$analysis$oDG)
##convert all runs to hzar.dataGroup objects
input.hzar$analysis$oDG <-hzar.make.obsDataGroup(input.hzar$analysis$initDGs)
input.hzar$analysis$oDG <-hzar.copyModelLabels(input.hzar$analysis$initDGs,input.hzar$analysis$oDG)
input.hzar$analysis$oDG <-hzar.make.obsDataGroup(lapply(input.hzar$runs$chains,hzar.dataGroup.add),input.hzar$analysis$oDG)
#this no longer works
#input.hzar$analysis$oDG <- hzar.make.obsDataGroup(lapply(input.hzar$runs$doSeq,   hzar.dataGroup.add),input.hzar$analysis$oDG)
#compare the 5 cline models graphically
print("output clines from each model overlaid")
hzar.plot.cline(input.hzar$analysis$oDG)
#model selection based on AICc scores
print("AICc table")
print(input.hzar$analysis$AICcTable<- hzar.AICc.hzar.obsDataGroup(input.hzar$analysis$oDG))
#Extract the hzar.dataGroup object for the selected model
print("best model based on AICc")
print(input.hzar$analysis$model.name<-   rownames(input.hzar$analysis$AICcTable)[[which.min(input.hzar$analysis$AICcTable$AICc)]])
input.hzar$analysis$model.selected<- input.hzar$analysis$oDG$data.groups[[input.hzar$analysis$model.name]]
#print the point estimates for cline width and center for the selected model
input.hzar$analysis$modeldetails <- hzar.get.ML.cline(input.hzar$analysis$model.selected)
input.hzar$analysis$modeldetails$param.all$width
input.hzar$analysis$modeldetails$param.all$center
#Print the 2LL confidence intervals for each parameter under the best model
print("2LL confidence intervals for all estimated parameters")
print(hzar.getLLCutParam(input.hzar$analysis$model.selected,   names(input.hzar$analysis$model.selected$data.param)))
#plot the maximum likelihood cline for the selected model
print("maximum likelihood cline")
hzar.plot.cline(input.hzar$analysis$model.selected,pch=19,xlab="Distance (km)",ylab=input.var)
#plot the 95% credible cline region for the selected model
print("95% credible cline region for the optimal model")
hzar.plot.fzCline(input.hzar$analysis$model.selected,pch=19,xlab="Distance (km)",ylab=input.var)
return(input.hzar)
}
mtDNA.input <- hzar.doMolecularData1DPops(distance=SD.locs$dist,
pObs=SD.locs$mtdna,
nEff=c(17,3,15,10,4,8,9,10,9,10,23))
library(hzar)
install.packages("hzar")
vcfR <- read.vcfR("~/Downloads/populations.snps.vcf")
library(vcfR) #v1.14.0
vcfR <- read.vcfR("~/Downloads/populations.snps.vcf")
rm(list=ls())
#load package
library(hzar)
setwd("~/Desktop/SNPfiltR/")
check()
devtools::check()
library(SNPfiltR)
library(vcfR)
#load the example vcfR object
data(vcfR.example)
### check the metadata present in your vcf
vcfR.example
vcfR.example@fix[1:10,1:8]
vcfR.example@gt[1:10,1:2]
#Load the example popmap file. It is a standard two column popmap, where the first column must be named 'id' and contain individual sample identifiers matching the sample identifiers in the vcf file, and the second column must be named 'pop', and contain a population assignment for each sample.
data(popmap)
popmap
#hard filter to minimum depth of 5, and minimum genotype quality of 30
vcfR<-hard_filter(vcfR=vcfR.example, depth = 5, gq = 30)
#execute allele balance filter
vcfR<-filter_allele_balance(vcfR)
#filter vcf by the max depth cutoff you chose
vcfR<-max_depth(vcfR, maxdepth = 100)
#check vcfR to see how many SNPs we have left
vcfR
#run function to visualize samples and return informative data.frame object
miss<-missing_by_sample(vcfR=vcfR)
#remove invariant sites generated by sample trimming and genotype filtering
vcfR<-min_mac(vcfR, min.mac = 1)
#update popmap by removing samples that have been filtered out
popmap<-popmap[popmap$id %in% colnames(vcfR@gt)[-1],]
#visualize missing data by SNP and the effect of various cutoffs on the missingness of each sample
missing_by_snp(vcfR)
#assess missing data effects on clustering
assess_missing_data_pca(vcfR = vcfR, popmap = popmap, thresholds = c(.8), clustering = FALSE)
assess_missing_data_tsne(vcfR = vcfR, popmap = popmap, thresholds = c(.8), clustering = FALSE)
gt.matrix<-vcfR::extract.gt(vcfR)
missingness.og<-sum(is.na(gt.matrix)) #store missingness
gt.matrix[gt.matrix == "0/0"]<-0
gt.matrix[gt.matrix == "0/1"]<-1
gt.matrix[gt.matrix == "1/0"]<-1
gt.matrix[gt.matrix == "1/1"]<-2
class(gt.matrix) <- "numeric"
missingness.new<-sum(is.na(gt.matrix)) #store missingness after the conversion
#if unrecognized genotype values were present throw an error
if (missingness.og != missingness.new){
stop("Unrecognized genotype values in input vcf. Only allowed genotype inputs are '0/0','0/1','1/0','1/1'.Use 'table(vcfR@gt)' to see your input genotypes.")
}
#calc sfs
sfs<-rowSums(gt.matrix, na.rm = TRUE)
#calc number of invariant SNPs
g<-sum(sfs < 1)
#If there are invariant SNPs, kill the function, and tell user that invariant SNPs aren't allowed
if (g != 0){
stop("invariant SNPs detected in input vcf. Invariant sites must be filtered prior to input")
}
gen<-vcfR::vcfR2genlight(vcfR)
pca<-adegenet::glPca(gen,
nf=length(levels(as.factor(popmap$pop)))+2)
length(levels(as.factor(popmap$pop)))+2
adegenet::glPca(gen)
View(gen)
gen@gen
gen
gen@position
View(gt.matrix)
#show me the samples with the most missing data at an 80% completeness threshold
filt<-miss$missing.by.filter[miss$missing.by.filter$filt == .8,]
filt[order(filt$snps.retained),]
check()
devtools::check()
