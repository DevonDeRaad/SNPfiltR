)
#convert each to a dataframe
y<-summary(y)
z<-summary(z)
#add these results into the full dataframe
sum.df<-rbind(sum.df,y,z)
#100K
#remove objects currently in the working directory to avoid internal memory issues slowing down the functions and affecting benchmarking accuracy
rm(x,y,z)
#now benchmark with having to read in the file itself
y<-microbenchmark(
#benchmark 100K while having to read in the vcf file
hard_filter(vcfR = read.vcfR("~/Desktop/benchmarking.vcfs/benchmark.100K.vcf"),depth = 5,gq = 30),
#set number of reps and units as seconds
times = 3, unit = "s"
)
#read in 100K benchmarking vcf
x<-read.vcfR("~/Desktop/benchmarking.vcfs/benchmark.100K.vcf")
#now benchmark without having to read in the file itself
z<-microbenchmark(
#benchmark 100K while having to read in the vcf file
hard_filter(vcfR = x, depth = 5, gq = 30),
#set number of reps and units as seconds
times = 3, unit = "s"
)
#convert each to a dataframe
y<-summary(y)
z<-summary(z)
#add these results into the full dataframe
sum.df<-rbind(sum.df,y,z)
View(sum.df)
View(sum.df)
View(sum.df)
library(SNPfiltR)
library(vcfR)
library(microbenchmark)
#10K
#now benchmark with having to read in the file itself
y<-microbenchmark(
#benchmark 10K while having to read in the vcf file
hard_filter(vcfR = read.vcfR("~/Desktop/benchmarking.vcfs/benchmark.10K.vcf"),depth = 5,gq = 30),
#set number of reps and units as seconds
times = 3, unit = "s"
)
View(sum.df)
#read in VCFtools times
vcftools.times<-read.table("~/Desktop/benchmarking.vcfs/cleantimes.txt", sep = "\t")
View(vcftools.times)
View(vcftools.times)
View(sum.df)
#make column 2 numeric
vcftools.times$V2<-gsub("0m", "", vcftools.times$V2)
View(vcftools.times)
vcftools.times$V2<-gsub("s", "", vcftools.times$V2)
vcftools.times$V2<-as.numeric(as.character(vcftools.times$V2))
View(vcftools.times)
library(SNPfiltR)
library(vcfR)
library(microbenchmark)
#10K
#now benchmark with having to read in the file itself
y<-microbenchmark(
#benchmark 10K while having to read in the vcf file
hard_filter(vcfR = read.vcfR("~/Desktop/benchmarking.vcfs/benchmark.10K.vcf"),depth = 5,gq = 30),
#set number of reps and units as seconds
times = 3, unit = "s"
)
#read in 10K benchmarking vcf
x<-read.vcfR("~/Desktop/benchmarking.vcfs/benchmark.10K.vcf")
#now benchmark without having to read in the file itself
z<-microbenchmark(
#benchmark 20K while having to read in the vcf file
hard_filter(vcfR = x, depth = 5, gq = 30),
#set number of reps and units as seconds
times = 3, unit = "s"
)
#convert each to a dataframe
y<-summary(y)
z<-summary(z)
#add these results into the full dataframe
sum.df<-rbind(y,z)
#20K
#remove objects currently in the working directory to avoid internal memory issues slowing down the functions and affecting benchmarking accuracy
rm(x,y,z)
#now benchmark with having to read in the file itself
y<-microbenchmark(
#benchmark 20K while having to read in the vcf file
hard_filter(vcfR = read.vcfR("~/Desktop/benchmarking.vcfs/benchmark.20K.vcf"),depth = 5,gq = 30),
#set number of reps and units as seconds
times = 3, unit = "s"
)
#read in 20K benchmarking vcf
x<-read.vcfR("~/Desktop/benchmarking.vcfs/benchmark.20K.vcf")
#now benchmark without having to read in the file itself
z<-microbenchmark(
#benchmark 20K while having to read in the vcf file
hard_filter(vcfR = x, depth = 5, gq = 30),
#set number of reps and units as seconds
times = 3, unit = "s"
)
#convert each to a dataframe
y<-summary(y)
z<-summary(z)
#add these results into the full dataframe
sum.df<-rbind(sum.df,y,z)
#50K
#remove objects currently in the working directory to avoid internal memory issues slowing down the functions and affecting benchmarking accuracy
rm(x,y,z)
#now benchmark with having to read in the file itself
y<-microbenchmark(
#benchmark 50K while having to read in the vcf file
hard_filter(vcfR = read.vcfR("~/Desktop/benchmarking.vcfs/benchmark.50K.vcf"),depth = 5,gq = 30),
#set number of reps and units as seconds
times = 3, unit = "s"
)
#read in 50K benchmarking vcf
x<-read.vcfR("~/Desktop/benchmarking.vcfs/benchmark.50K.vcf")
#now benchmark without having to read in the file itself
z<-microbenchmark(
#benchmark 50K while having to read in the vcf file
hard_filter(vcfR = x, depth = 5, gq = 30),
#set number of reps and units as seconds
times = 3, unit = "s"
)
#convert each to a dataframe
y<-summary(y)
z<-summary(z)
#add these results into the full dataframe
sum.df<-rbind(sum.df,y,z)
#100K
#remove objects currently in the working directory to avoid internal memory issues slowing down the functions and affecting benchmarking accuracy
rm(x,y,z)
#now benchmark with having to read in the file itself
y<-microbenchmark(
#benchmark 100K while having to read in the vcf file
hard_filter(vcfR = read.vcfR("~/Desktop/benchmarking.vcfs/benchmark.100K.vcf"),depth = 5,gq = 30),
#set number of reps and units as seconds
times = 3, unit = "s"
)
#read in 100K benchmarking vcf
x<-read.vcfR("~/Desktop/benchmarking.vcfs/benchmark.100K.vcf")
#now benchmark without having to read in the file itself
z<-microbenchmark(
#benchmark 100K while having to read in the vcf file
hard_filter(vcfR = x, depth = 5, gq = 30),
#set number of reps and units as seconds
times = 3, unit = "s"
)
#convert each to a dataframe
y<-summary(y)
z<-summary(z)
#add these results into the full dataframe
sum.df<-rbind(sum.df,y,z)
#200K
#remove objects currently in the working directory to avoid internal memory issues slowing down the functions and affecting benchmarking accuracy
rm(x,y,z)
#now benchmark with having to read in the file itself
y<-microbenchmark(
#benchmark 200K while having to read in the vcf file
hard_filter(vcfR = read.vcfR("~/Desktop/benchmarking.vcfs/benchmark.200K.vcf"),depth = 5,gq = 30),
#set number of reps and units as seconds
times = 3, unit = "s"
)
#read in 200K benchmarking vcf
x<-read.vcfR("~/Desktop/benchmarking.vcfs/benchmark.200K.vcf")
#now benchmark without having to read in the file itself
z<-microbenchmark(
#benchmark 200K while having to read in the vcf file
hard_filter(vcfR = x, depth = 5, gq = 30),
#set number of reps and units as seconds
times = 3, unit = "s"
)
#convert each to a dataframe
y<-summary(y)
z<-summary(z)
#add these results into the full dataframe
sum.df<-rbind(sum.df,y,z)
#300K
#remove objects currently in the working directory to avoid internal memory issues slowing down the functions and affecting benchmarking accuracy
rm(x,y,z)
#now benchmark with having to read in the file itself
y<-microbenchmark(
#benchmark 300K while having to read in the vcf file
hard_filter(vcfR = read.vcfR("~/Desktop/benchmarking.vcfs/benchmark.300K.vcf"),depth = 5,gq = 30),
#set number of reps and units as seconds
times = 3, unit = "s"
)
#read in 300K benchmarking vcf
x<-read.vcfR("~/Desktop/benchmarking.vcfs/benchmark.300K.vcf")
#now benchmark without having to read in the file itself
z<-microbenchmark(
#benchmark 300K while having to read in the vcf file
hard_filter(vcfR = x, depth = 5, gq = 30),
#set number of reps and units as seconds
times = 3, unit = "s"
)
#convert each to a dataframe
y<-summary(y)
z<-summary(z)
#add these results into the full dataframe
sum.df<-rbind(sum.df,y,z)
#400K
#remove objects currently in the working directory to avoid internal memory issues slowing down the functions and affecting benchmarking accuracy
rm(x,y,z)
#now benchmark with having to read in the file itself
y<-microbenchmark(
#benchmark 400K while having to read in the vcf file
hard_filter(vcfR = read.vcfR("~/Desktop/benchmarking.vcfs/benchmark.400K.vcf"),depth = 5,gq = 30),
#set number of reps and units as seconds
times = 3, unit = "s"
)
#read in 400K benchmarking vcf
x<-read.vcfR("~/Desktop/benchmarking.vcfs/benchmark.400K.vcf")
#now benchmark without having to read in the file itself
z<-microbenchmark(
#benchmark 400K while having to read in the vcf file
hard_filter(vcfR = x, depth = 5, gq = 30),
#set number of reps and units as seconds
times = 3, unit = "s"
)
#convert each to a dataframe
y<-summary(y)
z<-summary(z)
#add these results into the full dataframe
sum.df<-rbind(sum.df,y,z)
#500K
#remove objects currently in the working directory to avoid internal memory issues slowing down the functions and affecting benchmarking accuracy
rm(x,y,z)
#now benchmark with having to read in the file itself
y<-microbenchmark(
#benchmark 500K while having to read in the vcf file
hard_filter(vcfR = read.vcfR("~/Desktop/benchmarking.vcfs/benchmark.500K.vcf"),depth = 5,gq = 30),
#set number of reps and units as seconds
times = 3, unit = "s"
)
#read in 500K benchmarking vcf
x<-read.vcfR("~/Desktop/benchmarking.vcfs/benchmark.500K.vcf")
#now benchmark without having to read in the file itself
z<-microbenchmark(
#benchmark 500K while having to read in the vcf file
hard_filter(vcfR = x, depth = 5, gq = 30),
#set number of reps and units as seconds
times = 3, unit = "s"
)
#convert each to a dataframe
y<-summary(y)
z<-summary(z)
#add these results into the full dataframe
sum.df<-rbind(sum.df,y,z)
sum.df$approach<-rep(c("SNPfiltR+vcfR","SNPfiltR"), times = 8)
sum.df$SNPs<-c(10000,10000,20000,20000,50000,50000,100000,100000,
200000,200000,300000,300000,400000,400000,500000,500000)
#read in VCFtools times
vcftools.times<-read.table("~/Desktop/benchmarking.vcfs/cleantimes.txt", sep = "\t")
View(vcftools.times)
#make column 2 numeric
vcftools.times$V2<-gsub("*m", "", vcftools.times$V2)
View(vcftools.times)
#read in VCFtools times
vcftools.times<-read.table("~/Desktop/benchmarking.vcfs/cleantimes.txt", sep = "\t")
View(vcftools.times)
#make column 2 numeric
vcftools.times$V2<-gsub("0m", "", vcftools.times$V2)
View(vcftools.times)
View(vcftools.times)
vcftools.times$V2<-gsub("1m", "", vcftools.times$V2)
vcftools.times$V2<-gsub("s", "", vcftools.times$V2)
vcftools.times$V2<-as.numeric(as.character(vcftools.times$V2))
vcftools.times$V2[22:24]+60
View(vcftools.times)
View(vcftools.times)
#make column 1 informative about run conditions
vcftools.times$V1<-c(rep(10000, times=3),rep(20000, times=3),rep(50000, times=3),
rep(100000, times=3),rep(200000, times=3),rep(300000, times=3),
rep(400000, times=3),rep(500000, times=3))
View(vcftools.times)
View(sum.df)
#
colnames(vcftools.times)<-c("SNPs","run.time")
View(vcftools.times)
View(vcftools.times)
View(sum.df)
#add column tagging all of these times as coming from vcftools
vcftools.times$method<-rep("vcftools", times=nrow(vcftools.times))
View(vcftools.times)
View(sum.df)
SNPfiltR.times<-sum.df[,c(9,10,4)]
View(SNPfiltR.times)
View(vcftools.times)
View(SNPfiltR.times)
summary(vcftools.times)
#
aggregate(vcftools.times$run.time, list(vcftools.times$SNPs), mean)
#
v<-aggregate(vcftools.times$run.time, list(vcftools.times$SNPs), mean)
View(v)
vcftools.times<-read.table("~/Desktop/benchmarking.vcfs/cleantimes.txt", sep = "\t")
#make column 1 informative about run conditions
vcftools.times$V1<-c(rep(10000, times=3),rep(20000, times=3),rep(50000, times=3),
rep(100000, times=3),rep(200000, times=3),rep(300000, times=3),
rep(400000, times=3),rep(500000, times=3))
#make column 2 numeric
vcftools.times$V2<-gsub("0m", "", vcftools.times$V2)
vcftools.times$V2<-gsub("1m", "", vcftools.times$V2)
vcftools.times$V2<-gsub("s", "", vcftools.times$V2)
vcftools.times$V2<-as.numeric(as.character(vcftools.times$V2))
#account for the last 3 which took over a minute
vcftools.times$V2[22:24]<-vcftools.times$V2[22:24]+60
#give informative column names
colnames(vcftools.times)<-c("SNPs","run.time")
#
v<-aggregate(vcftools.times$run.time, list(vcftools.times$SNPs), mean)
View(v)
vcftools.times<-read.table("~/Desktop/benchmarking.vcfs/cleantimes.txt", sep = "\t")
#make column 1 informative about run conditions
vcftools.times$V1<-c(rep(10000, times=3),rep(20000, times=3),rep(50000, times=3),
rep(100000, times=3),rep(200000, times=3),rep(300000, times=3),
rep(400000, times=3),rep(500000, times=3))
#make column 2 numeric
vcftools.times$V2<-gsub("0m", "", vcftools.times$V2)
vcftools.times$V2<-gsub("1m", "", vcftools.times$V2)
vcftools.times$V2<-gsub("s", "", vcftools.times$V2)
vcftools.times$V2<-as.numeric(as.character(vcftools.times$V2))
#account for the last 3 which took over a minute
vcftools.times$V2[22:24]<-vcftools.times$V2[22:24]+60
View(vcftools.times)
#
v<-aggregate(vcftools.times$V2, list(vcftools.times$V1), mean)
View(v)
#add column tagging all of these times as coming from vcftools
v$method<-rep("vcftools", times=nrow(v))
View(v)
#
v<-aggregate(vcftools.times$V2, list(vcftools.times$V1), mean)
#add column tagging all of these times as coming from vcftools
v$approach<-rep("vcftools", times=nrow(v))
View(v)
#give informative column names
colnames(v)[1:2]<-c("SNPs","run.time")
#give informative column names
colnames(v)[1:2]<-c("SNPs","mean")
#reorder to match column order from microbenchmark
v<-v[,c(3,1,2)]
#rbind dataframes
benchmark.df<-rbind(SNPfiltR.times,v)
View(benchmark.df)
class(benchmark.df$approach)
as.factor(benchmark.df$approach)
benchmark.df$approach<-as.factor(benchmark.df$approach)
class(benchmark.df$SNPs)
class(benchmark.df$mean)
library(ggplot2)
View(benchmark.df)
#visualize the comparative runtimes across SNPs and between approaches
ggplot(benchmark.df, aes(x = SNPs, y = mean, color = approach)) +
geom_point(aes(fill=approach),size=3) +
geom_line(aes(group = approach),
arrow = arrow(type = "closed",
length=unit(0.075, "inches")))
#visualize the comparative runtimes across SNPs and between approaches
ggplot(benchmark.df, aes(x = SNPs, y = mean, color = approach)) +
geom_point(aes(fill=approach),size=3) +
geom_line(aes(group = approach))
#visualize the comparative runtimes across SNPs and between approaches
ggplot(benchmark.df, aes(x = SNPs, y = mean, color = approach)) +
geom_point(aes(fill=approach),size=3) +
geom_line(aes(group = approach))+
theme_classic()
#visualize the comparative runtimes across SNPs and between approaches
ggplot(benchmark.df, aes(x = SNPs, y = mean, color = approach)) +
geom_point(aes(fill=approach),size=3) +
geom_line(aes(group = approach))+
theme_classic()+
ylab("mean runtime (seconds)")
#visualize the comparative runtimes across SNPs and between approaches
ggplot(benchmark.df, aes(x = SNPs, y = mean, color = approach)) +
geom_point(aes(fill=approach),size=3) +
geom_line(aes(group = approach))+
scale_x_log10()+
theme_classic()+
ylab("mean runtime (seconds)")
#visualize the comparative runtimes across SNPs and between approaches
ggplot(benchmark.df, aes(x = SNPs, y = mean, color = approach)) +
geom_point(aes(fill=approach),size=3) +
geom_line(aes(group = approach))+
theme_classic()+
ylab("mean runtime (seconds)")
#visualize the comparative runtimes across SNPs and between approaches
ggplot(benchmark.df, aes(x = SNPs, y = mean, color = approach)) +
geom_point(aes(fill=approach),size=3) +
geom_line(aes(group = approach))+
theme_classic()+
ylab("mean runtime (seconds)")+
#try it with a log10 scaled x axis
ggplot(benchmark.df, aes(x = SNPs, y = mean, color = approach)) +
geom_point(aes(fill=approach),size=3) +
geom_line(aes(group = approach))+
scale_x_log10()+
theme_classic()+
ylab("mean runtime (seconds)")+
scale_fill_discrete(name = "gk")
#visualize the comparative runtimes across SNPs and between approaches
ggplot(benchmark.df, aes(x = SNPs, y = mean, color = approach)) +
geom_point(aes(fill=approach),size=3) +
geom_line(aes(group = approach))+
theme_classic()+
ylab("mean runtime (seconds)")+
#try it with a log10 scaled x axis
ggplot(benchmark.df, aes(x = SNPs, y = mean, color = approach)) +
geom_point(aes(fill=approach),size=3) +
geom_line(aes(group = approach))+
scale_x_log10()+
theme_classic()+
ylab("mean runtime (seconds)")
#try it with a log10 scaled x axis
ggplot(benchmark.df, aes(x = SNPs, y = mean, color = approach)) +
geom_point(aes(fill=approach),size=3) +
geom_line(aes(group = approach))+
scale_x_log10()+
theme_classic()+
ylab("mean runtime (seconds)")+
scale_fill_discrete(name = "gk")
vcftools.times<-read.table("~/Desktop/benchmarking.vcfs/cleantimes.txt", sep = "\t")
#make column 1 informative about run conditions
vcftools.times$V1<-c(rep(10000, times=3),rep(20000, times=3),rep(50000, times=3),
rep(100000, times=3),rep(200000, times=3),rep(300000, times=3),
rep(400000, times=3),rep(500000, times=3))
#make column 2 numeric
vcftools.times$V2<-gsub("0m", "", vcftools.times$V2)
vcftools.times$V2<-gsub("1m", "", vcftools.times$V2)
vcftools.times$V2<-gsub("s", "", vcftools.times$V2)
vcftools.times$V2<-as.numeric(as.character(vcftools.times$V2))
#account for the last 3 which took over a minute
vcftools.times$V2[22:24]<-vcftools.times$V2[22:24]+60
#get the mean of the runtimes across all three replicates, for each vcf file
v<-aggregate(vcftools.times$V2, list(vcftools.times$V1), mean)
#add column tagging all of these times as coming from vcftools
v$approach<-rep("VCFtools", times=nrow(v))
#give informative column names
colnames(v)[1:2]<-c("SNPs","mean")
#reorder to match column order from microbenchmark
v<-v[,c(3,1,2)]
#rbind dataframe with the microbenchmark dataframe
benchmark.df<-rbind(SNPfiltR.times,v)
#make approach a factor for plotting
benchmark.df$approach<-as.factor(benchmark.df$approach)
#final product:
benchmark.df
ggplot(benchmark.df, aes(x = SNPs, y = mean, color = approach)) +
geom_point(aes(fill=approach),size=3) +
geom_line(aes(group = approach))+
theme_classic()+
ylab("mean runtime (seconds)")
#visualize the comparative runtimes across SNPs and between approaches
ggplot(benchmark.df, aes(x = SNPs, y = mean, color = approach)) +
geom_point(aes(fill=approach),size=3) +
geom_line(aes(group = approach))+
theme_classic()+
ylab("mean runtime (seconds)")+
theme(legend.position = c(0.2, 0.8))
#try it with a log10 scaled x axis
ggplot(benchmark.df, aes(x = SNPs, y = mean, color = approach)) +
geom_point(aes(fill=approach),size=3) +
geom_line(aes(group = approach))+
scale_x_log10()+
theme_classic()+
ylab("mean runtime (seconds)")+
theme(legend.position = c(0.2, 0.8))
#visualize the comparative runtimes across SNPs and between approaches
ggplot(benchmark.df, aes(x = SNPs, y = mean, color = approach)) +
geom_point(aes(fill=approach),size=3) +
geom_line(aes(group = approach))+
theme_classic()+
ylab("mean runtime (seconds)")+
xlab("SNPs in input vcf")+
theme(legend.position = c(0.2, 0.8))
#visualize the comparative runtimes across SNPs and between approaches
ggplot(benchmark.df, aes(x = SNPs, y = mean, color = approach)) +
geom_point(aes(fill=approach),size=3) +
geom_line(aes(group = approach))+
theme_classic()+
ylab("mean runtime (seconds)")+
theme(legend.position = c(0.2, 0.8))
runtime.plot<-ggplot(benchmark.df, aes(x = SNPs, y = mean, color = approach)) +
geom_point(aes(fill=approach),size=3) +
geom_line(aes(group = approach))+
theme_classic()+
ylab("mean runtime (seconds)")+
theme(legend.position = c(0.2, 0.8))
ggsave(runtime.plot,
filename = "~/Desktop/SNPfiltR.mol.ecol.resour.submission/comp.runtimes.pdf",
height = 4, width = 6, units = "in")
ggsave(runtime.plot,
filename = "~/Desktop/SNPfiltR.mol.ecol.resour.submission/comp.runtimes.pdf",
height = 3, width = 4, units = "in")
build()
library(devtools)
build_site()
write.csv(benchmark.df, file="~/Desktop/benchmarking.vcfs/benchmark.info.csv", quote = F, row.names = F)
build_site()
SNPfiltR::example_vcfR
library(SNPfiltR)
SNPfiltR::vcfR.example
class(SNPfiltR::vcfR.example)
install.packages(‘SNPfiltR’); data(SNPfiltR::example.vcfR)
install.packages('SNPfiltR'); data(SNPfiltR::example.vcfR)
sum(6,9); data(SNPfiltR::vcfR.example)
SNPfiltR::vcfR.example
data(SNPfiltR::vcfR.example)
data(vcfR.example)
build_site()
build_site()
